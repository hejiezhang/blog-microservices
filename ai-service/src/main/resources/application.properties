spring.application.name=ai-service

server.port=8084

#spring.ai.ollama.chat.options.model=llama3.2
#spring.ai.ollama.base-url=http://localhost:11434
#spring.ai.ollama.chat.options.temperature=0.7

spring.ai.openai.chat.base-url=http://localhost:11434
spring.ai.openai.chat.options.model=llama3.2
spring.ai.openai.chat.options.temperature=0.7
spring.ai.openai.api-key=none


logging.file.name=logs/ai-service.log
logging.level.root=INFO
# Log pattern
# logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n